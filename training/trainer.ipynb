{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for a classification model\n",
    "\n",
    "- the main goal is to fit the best category for a given handicraft product in the database;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import dotenv\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "from datetime import date\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the environment varibables\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "dataset_path = os.getenv(\"DATASET_PATH\")\n",
    "metrics_path = os.getenv(\"METRICS_PATH\")\n",
    "model_path = os.getenv(\"MODEL_PATH\")\n",
    "test_path = os.getenv(\"TEST_PATH\")\n",
    "\n",
    "stop_words = stopwords.words(\"portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "sample = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick glimpse at the dataset\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the type and other information of each variable\n",
    "sample.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Taking a look at the correlation between the numerical variables and categories so one can have an insight for a possible relevant feature;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.concat([sample, pd.get_dummies(sample.category)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.corr().loc[sample.category.unique()].style.background_gradient(cmap = \"inferno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The word clouds ahead help us to understand how the textual features, like queries and title, behave for each category, in such way that make it an interesting feature to use in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cloud_feature(feature: str):\n",
    "    \"\"\" a function to loop over and create wordclouds for each label of the dataset \"\"\"\n",
    "    for category in sample.category.unique():\n",
    "        words = \" \".join(word for word in sample.query(f\"category == '{category}'\")[feature].dropna())\n",
    "\n",
    "        cloud = WordCloud(\n",
    "            stopwords = stop_words,\n",
    "            background_color = \"white\",\n",
    "            colormap = \"inferno\",\n",
    "            width = 800,\n",
    "            height = 800\n",
    "        ).generate(words)\n",
    "\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.title(category, fontweight = \"bold\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(cloud, interpolation = \"bilinear\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_feature(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_feature(\"query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_feature(\"concatenated_tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "- using holdout to evalute the model;\n",
    "- encode the label to have numerical values for each category;\n",
    "- bag of words to process the `concatenated_tags` and `title` features;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the features and label\n",
    "X = sample[[\"concatenated_tags\", \"title\"]]\n",
    "y = sample[\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.fillna(\"\", inplace = True)\n",
    "X = X.apply(lambda x: x.str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the label (dependent variable)\n",
    "enc = LabelEncoder()\n",
    "\n",
    "enc.fit(y)\n",
    "\n",
    "y_enc = enc.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words = stop_words)\n",
    "\n",
    "X_tags = count_vectorizer.fit_transform(X.concatenated_tags)\n",
    "\n",
    "X_title = count_vectorizer.transform(X.title)\n",
    "\n",
    "X_array = sparse.hstack((X_tags, X_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_array, y_enc, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "- given the fact that the dependent variable (category) is of type object (categorical, if you will) we might use the logistic regression;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "\n",
    "model = logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_report = metrics.classification_report(y_val, y_pred, target_names = enc.classes_)\n",
    "print(metrics_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(metrics_path, \"w\") as file:\n",
    "    file.write(f\"Model: {model}\\ndate: {date.today()}\\n\\n\")\n",
    "    file.write(f\"Metrics:\\n{metrics_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "with open(model_path, \"wb\") as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "- applying the model to the test dataset;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_sample[[\"concatenated_tags\", \"title\"]]\n",
    "y_test = test_sample[\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.fillna(\"\", inplace = True)\n",
    "X_test = X_test.apply(lambda x: x.str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_enc = enc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tags = count_vectorizer.transform(X_test.concatenated_tags)\n",
    "\n",
    "X_test_title = count_vectorizer.transform(X_test.title)\n",
    "\n",
    "X_test_array = sparse.hstack((X_test_tags, X_test_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test_enc, y_test_pred, target_names = enc.classes_))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a462faffccb8aa22236aa0e5a09c25c39cca3b804353f62c791d889f65c46e45"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('3.9.5': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
